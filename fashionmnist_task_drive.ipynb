{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahsan-folium/ai-intern-week04-deep-learnin/blob/main/fashionmnist_task_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# For optimization algorithms like SGD and Adam\n",
        "import torch.optim as optim\n",
        "\n",
        "# For datasets like Fashion-MNIST\n",
        "import torchvision\n",
        "\n",
        "# To transform data\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "B3P-dl3yWGZn"
      },
      "id": "B3P-dl3yWGZn",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET AND DATA"
      ],
      "metadata": {
        "id": "y1p1x7G7cyoZ"
      },
      "id": "y1p1x7G7cyoZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "\n",
        "\n",
        "# Transform: Convert images to tensors and normalize to range [-1, 1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert PIL images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize: mean=0.5, std=0.5\n",
        "])\n"
      ],
      "metadata": {
        "id": "PVTgBfNLY4bH"
      },
      "id": "PVTgBfNLY4bH",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download training dataset and testing dataset\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(\n",
        "    root='./data' ,\n",
        "    train=True ,\n",
        "    download=True ,\n",
        "    transform= transform\n",
        "\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(\n",
        "    root='./data' ,\n",
        "    train= False ,\n",
        "    download=True ,\n",
        "    transform= transform\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZA9Ha3PaM16",
        "outputId": "94aceb2b-d6ee-4fb3-fe01-2a2c05a649dc"
      },
      "id": "hZA9Ha3PaM16",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 17.1MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 275kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 4.51MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 13.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes for undertanding**\n",
        "\n",
        "ToTensor() converts images from [0,255] to [0,1].\n",
        "\n",
        "Normalize((0.5,), (0.5,)) scales data to roughly [-1,1], which helps training stability.\n",
        "\n",
        "DataLoader creates mini-batches for faster training and supports shuffling.\n",
        "\n",
        "Some typical choices:\n",
        "\n",
        "32, 64, 128, 256\n",
        "\n",
        "Must balance between:\n",
        "\n",
        "Small batch size (like 16 or 32):\n",
        "\n",
        "Large batch size (like 256, 512):\n",
        "\n",
        "👉 So:\n",
        "batch_size=64 means \"process 64 images at a time\". It’s chosen because it’s a good balance of speed, memory usage, and model performance."
      ],
      "metadata": {
        "id": "ZDRpXfCea42n"
      },
      "id": "ZDRpXfCea42n"
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size= 64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size= 64,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "u9bkz957bCmg"
      },
      "id": "u9bkz957bCmg",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NEURAL NETWORK"
      ],
      "metadata": {
        "id": "ukZVW3Njca9W"
      },
      "id": "ukZVW3Njca9W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**input size** is always accoridng to dataset , this dataset has 28*28 images\n",
        "\n",
        "**output size** is determined by the number of classes in your classification problem.\n",
        "\n",
        "Fashion-MNIST has 10 categories → output_size = 10.\n",
        "\n",
        "\n",
        "**Hidden layers (what you experiment with)**\n",
        "\n",
        "\n",
        "\n",
        "Number of hidden layers (1, 2, 3, …).\n",
        "\n",
        "Size of hidden layers (64 neurons, 128, 256, etc.).\n",
        "\n",
        "Activation functions (ReLU, Sigmoid, Tanh, …).\n",
        "\n",
        "These are your design choices. Changing them changes how powerful or efficient your model is."
      ],
      "metadata": {
        "id": "3v_YPEWwkEk2"
      },
      "id": "3v_YPEWwkEk2"
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNN(nn.Module):\n",
        "  def __init__(self , hidden_size , activation, input_size = 28*28  , output_size=10):\n",
        "    super(FashionNN,self).__init__()\n",
        "\n",
        "    # 2 fully connected layers , as we are implementing a feed forward NN\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "\n",
        "    # activation function : relu / sigmoid\n",
        "    if activation == 'relu':\n",
        "      self.activation = nn.ReLU()\n",
        "    elif activation == 'sigmoid':\n",
        "      self.activation = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    # forwad pass\n",
        "\n",
        "  def forward(self, x):\n",
        "       # Flatten the image (28x28) to a vector (784,)\n",
        "    x = x.view(x.size(0),-1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "9DFI2obJdErB"
      },
      "id": "9DFI2obJdErB",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**notes**\n",
        "\n",
        "fully connected layers (nn.Linear) expect 1D vectors, not 2D images. since we have images we have to flatten them\n",
        "\n",
        "So if your input is:\n",
        "\n",
        "[64, 1, 28, 28]   # 64 images in the batch\n",
        "\n",
        "\n",
        "After x.view(x.size(0), -1) →\n",
        "\n",
        "[64, 784]         # 64 flattened vectors, each of length 784"
      ],
      "metadata": {
        "id": "Le2PiiCwigDS"
      },
      "id": "Le2PiiCwigDS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First i made them without functions , but now i m converting to functions so i can play with different optimizers and activation functions and get the most accurate one**"
      ],
      "metadata": {
        "id": "jrlWwuTDvqNn"
      },
      "id": "jrlWwuTDvqNn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "He_fs8TZneGd"
      },
      "id": "He_fs8TZneGd"
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW WE CREATE THE MODEL , define loss and optimizer\n",
        "\n",
        "def create_model(hidden_size, activation , optimizer , lr):\n",
        "  # relu / sigmoid\n",
        "  model = FashionNN(\n",
        "    hidden_size = hidden_size ,\n",
        "    activation= activation\n",
        "  )\n",
        "\n",
        "  # Loss function\n",
        "  criterion = nn.CrossEntropyLoss() # Good for multi-class classification\n",
        "  # CrossEntropyLoss combines LogSoftmax + NLLLoss, perfect for classification.\n",
        "\n",
        "\n",
        "  # Choose optimizer: SGD or Adam\n",
        "  optimizer_choice = optimizer\n",
        "\n",
        "  if optimizer_choice == 'sgd':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  elif optimizer_choice == 'adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  return model, criterion, optimizer\n"
      ],
      "metadata": {
        "id": "hFjcnFc1ismD"
      },
      "id": "hFjcnFc1ismD",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the network"
      ],
      "metadata": {
        "id": "KJ9sJEGCnryH"
      },
      "id": "KJ9sJEGCnryH"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataset ,criterion, optimizer, epochs):\n",
        "\n",
        "  epochs = 5  # Number of times the model will see the entire dataset\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_dataset:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "aBq-0K5HoBqB"
      },
      "id": "aBq-0K5HoBqB",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the network"
      ],
      "metadata": {
        "id": "vrU9v8z0oNHT"
      },
      "id": "vrU9v8z0oNHT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**notes**\n",
        "outputs.data → raw tensor values (we don’t need gradient history).\n",
        "\n",
        "torch.max(tensor, dim=1) → find the maximum along dimension 1 (the class scores).\n",
        "\n",
        "Returns (values, indices) → values = max score, indices = where it occurred.\n",
        "\n",
        "_ means “ignore values, we only care about indices”.\n",
        "\n",
        "predicted shape = [batch_size], containing predicted class IDs.\n",
        "\n",
        "\n",
        "labels.size(0) = batch size (number of images in this batch).\n",
        "\n",
        "Add to total."
      ],
      "metadata": {
        "id": "9yEX1sRcsAxG"
      },
      "id": "9yEX1sRcsAxG"
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_dataset):\n",
        "\n",
        "  correct = 0   # to keep track of right number of predictions\n",
        "  total = 0\n",
        "\n",
        "  # Normally, PyTorch tracks every operation for backpropagation.\n",
        "  # But in testing, we don’t update weights → we don’t need gradients.\n",
        "\n",
        "  with torch.no_grad(): # No need to compute gradients\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) # Index of max logit = predicted class\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "  print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "i6OKfBXmrCOy"
      },
      "id": "i6OKfBXmrCOy",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "41uWv4mqrw-D"
      },
      "id": "41uWv4mqrw-D"
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model, criterion, optimizer = create_model(\n",
        "    hidden_size= 128 ,\n",
        "    activation= 'relu' ,\n",
        "    optimizer= 'adam' ,\n",
        "    lr= 0.001\n",
        "    )\n",
        "\n",
        "# train\n",
        "\n",
        "train_model(model, trainloader, criterion, optimizer, epochs=5)\n",
        "\n",
        "# test\n",
        "test_model(model,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDYDNKo8xG6i",
        "outputId": "9688d7bb-02f7-4f46-d187-d549308cb5a7"
      },
      "id": "qDYDNKo8xG6i",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5017\n",
            "Epoch [2/5], Loss: 0.3808\n",
            "Epoch [3/5], Loss: 0.3424\n",
            "Epoch [4/5], Loss: 0.3149\n",
            "Epoch [5/5], Loss: 0.2996\n",
            "Test Accuracy: 86.44%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.44"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rIo8Pi2oxusm"
      },
      "id": "rIo8Pi2oxusm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "eOOWkS6v0o-s"
      },
      "id": "eOOWkS6v0o-s"
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model2, criterion2, optimizer2 = create_model(\n",
        "    hidden_size= 256 ,\n",
        "    activation= 'sigmoid' ,\n",
        "    optimizer= 'adam' ,\n",
        "    lr= 0.001\n",
        "    )\n",
        "\n",
        "# train\n",
        "\n",
        "train_model(model2, trainloader, criterion2, optimizer2, epochs=5)\n",
        "\n",
        "# test\n",
        "test_model(model2,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2542927-7ef4-4ba2-b47b-639ae9157d34",
        "id": "O83Xz-gp0o-t"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5401\n",
            "Epoch [2/5], Loss: 0.3886\n",
            "Epoch [3/5], Loss: 0.3490\n",
            "Epoch [4/5], Loss: 0.3207\n",
            "Epoch [5/5], Loss: 0.3001\n",
            "Test Accuracy: 87.11%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.11"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "id": "O83Xz-gp0o-t"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpI-lAP20o-u"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hpI-lAP20o-u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "NDT79xEm0r0R"
      },
      "id": "NDT79xEm0r0R"
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model3, criterion3, optimizer3 = create_model(\n",
        "    hidden_size= 128 ,\n",
        "    activation= 'sigmoid' ,\n",
        "    optimizer= 'sgd' ,\n",
        "    lr= 0.01\n",
        "    )\n",
        "\n",
        "# train\n",
        "\n",
        "train_model(model3, trainloader, criterion3, optimizer3, epochs=5)\n",
        "\n",
        "# test\n",
        "test_model(model3,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81ac1b4-ae8d-43c5-8a3d-98f7c550bf8b",
        "id": "jc6DzBIj0r0S"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.5136\n",
            "Epoch [2/5], Loss: 0.9009\n",
            "Epoch [3/5], Loss: 0.7321\n",
            "Epoch [4/5], Loss: 0.6558\n",
            "Epoch [5/5], Loss: 0.6087\n",
            "Test Accuracy: 78.32%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.32"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "id": "jc6DzBIj0r0S"
    },
    {
      "cell_type": "code",
      "source": [
        "# as we can see model 2 has best accuracy , so we save the best model\n",
        "# Save weights + hyperparams in one checkpoint\n",
        "torch.save({\n",
        "    \"hidden_size\": 256,\n",
        "    \"activation\": \"sigmoid\",\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"state_dict\": model2.state_dict()\n",
        "}, \"model2.pt\")\n",
        "\n",
        "print(\"Model saved as model2.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIqMfbuT0r0S",
        "outputId": "78e1541a-4332-4748-ccc1-fb0bfa6081ab"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as model2.pt\n"
          ]
        }
      ],
      "id": "oIqMfbuT0r0S"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLf3my8Q3ETA",
        "outputId": "a1c966d0-df00-4cd6-dd0f-7b77c2e1a476"
      },
      "id": "BLf3my8Q3ETA",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 808K\n",
            "drwxr-xr-x 3 root root 4.0K Aug 20 07:39 data\n",
            "-rw-r--r-- 1 root root 798K Aug 20 09:43 model2.pt\n",
            "drwxr-xr-x 1 root root 4.0K Aug 18 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzKpZgb83ewV"
      },
      "id": "NzKpZgb83ewV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}