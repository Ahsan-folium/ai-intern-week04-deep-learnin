{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahsan-folium/ai-intern-week04-deep-learnin/blob/main/fashionmnist_task_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# For optimization algorithms like SGD and Adam\n",
        "import torch.optim as optim\n",
        "\n",
        "# For datasets like Fashion-MNIST\n",
        "import torchvision\n",
        "\n",
        "# To transform data\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "B3P-dl3yWGZn"
      },
      "id": "B3P-dl3yWGZn",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET AND DATA"
      ],
      "metadata": {
        "id": "y1p1x7G7cyoZ"
      },
      "id": "y1p1x7G7cyoZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "\n",
        "\n",
        "# Transform: Convert images to tensors and normalize to range [-1, 1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Convert PIL images to PyTorch tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize: mean=0.5, std=0.5\n",
        "])\n"
      ],
      "metadata": {
        "id": "PVTgBfNLY4bH"
      },
      "id": "PVTgBfNLY4bH",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download training dataset and testing dataset\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(\n",
        "    root='./data' ,\n",
        "    train=True ,\n",
        "    download=True ,\n",
        "    transform= transform\n",
        "\n",
        ")\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(\n",
        "    root='./data' ,\n",
        "    train= False ,\n",
        "    download=True ,\n",
        "    transform= transform\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZA9Ha3PaM16",
        "outputId": "94aceb2b-d6ee-4fb3-fe01-2a2c05a649dc"
      },
      "id": "hZA9Ha3PaM16",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.4M/26.4M [00:01<00:00, 17.1MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29.5k/29.5k [00:00<00:00, 275kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.42M/4.42M [00:00<00:00, 4.51MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.15k/5.15k [00:00<00:00, 13.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes for undertanding**\n",
        "\n",
        "ToTensor() converts images from [0,255] to [0,1].\n",
        "\n",
        "Normalize((0.5,), (0.5,)) scales data to roughly [-1,1], which helps training stability.\n",
        "\n",
        "DataLoader creates mini-batches for faster training and supports shuffling.\n",
        "\n",
        "Some typical choices:\n",
        "\n",
        "32, 64, 128, 256\n",
        "\n",
        "Must balance between:\n",
        "\n",
        "Small batch size (like 16 or 32):\n",
        "\n",
        "Large batch size (like 256, 512):\n",
        "\n",
        "ðŸ‘‰ So:\n",
        "batch_size=64 means \"process 64 images at a time\". Itâ€™s chosen because itâ€™s a good balance of speed, memory usage, and model performance."
      ],
      "metadata": {
        "id": "ZDRpXfCea42n"
      },
      "id": "ZDRpXfCea42n"
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,\n",
        "    batch_size= 64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size= 64,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "u9bkz957bCmg"
      },
      "id": "u9bkz957bCmg",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NEURAL NETWORK"
      ],
      "metadata": {
        "id": "ukZVW3Njca9W"
      },
      "id": "ukZVW3Njca9W"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**input size** is always accoridng to dataset , this dataset has 28*28 images\n",
        "\n",
        "**output size** is determined by the number of classes in your classification problem.\n",
        "\n",
        "Fashion-MNIST has 10 categories â†’ output_size = 10.\n",
        "\n",
        "\n",
        "**Hidden layers (what you experiment with)**\n",
        "\n",
        "\n",
        "\n",
        "Number of hidden layers (1, 2, 3, â€¦).\n",
        "\n",
        "Size of hidden layers (64 neurons, 128, 256, etc.).\n",
        "\n",
        "Activation functions (ReLU, Sigmoid, Tanh, â€¦).\n",
        "\n",
        "These are your design choices. Changing them changes how powerful or efficient your model is."
      ],
      "metadata": {
        "id": "3v_YPEWwkEk2"
      },
      "id": "3v_YPEWwkEk2"
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNN(nn.Module):\n",
        "  def __init__(self , hidden_size , activation, input_size = 28*28  , output_size=10):\n",
        "    super(FashionNN,self).__init__()\n",
        "\n",
        "    # 2 fully connected layers , as we are implementing a feed forward NN\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "\n",
        "    # activation function : relu / sigmoid\n",
        "    if activation == 'relu':\n",
        "      self.activation = nn.ReLU()\n",
        "    elif activation == 'sigmoid':\n",
        "      self.activation = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    # forwad pass\n",
        "\n",
        "  def forward(self, x):\n",
        "       # Flatten the image (28x28) to a vector (784,)\n",
        "    x = x.view(x.size(0),-1)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "9DFI2obJdErB"
      },
      "id": "9DFI2obJdErB",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**notes**\n",
        "\n",
        "fully connected layers (nn.Linear) expect 1D vectors, not 2D images. since we have images we have to flatten them\n",
        "\n",
        "So if your input is:\n",
        "\n",
        "[64, 1, 28, 28]   # 64 images in the batch\n",
        "\n",
        "\n",
        "After x.view(x.size(0), -1) â†’\n",
        "\n",
        "[64, 784]         # 64 flattened vectors, each of length 784"
      ],
      "metadata": {
        "id": "Le2PiiCwigDS"
      },
      "id": "Le2PiiCwigDS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First i made them without functions , but now i m converting to functions so i can play with different optimizers and activation functions and get the most accurate one**"
      ],
      "metadata": {
        "id": "jrlWwuTDvqNn"
      },
      "id": "jrlWwuTDvqNn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "He_fs8TZneGd"
      },
      "id": "He_fs8TZneGd"
    },
    {
      "cell_type": "code",
      "source": [
        "# NOW WE CREATE THE MODEL , define loss and optimizer\n",
        "\n",
        "def create_model(hidden_size, activation , optimizer , lr):\n",
        "  # relu / sigmoid\n",
        "  model = FashionNN(\n",
        "    hidden_size = hidden_size ,\n",
        "    activation= activation\n",
        "  )\n",
        "\n",
        "  # Loss function\n",
        "  criterion = nn.CrossEntropyLoss() # Good for multi-class classification\n",
        "  # CrossEntropyLoss combines LogSoftmax + NLLLoss, perfect for classification.\n",
        "\n",
        "\n",
        "  # Choose optimizer: SGD or Adam\n",
        "  optimizer_choice = optimizer\n",
        "\n",
        "  if optimizer_choice == 'sgd':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  elif optimizer_choice == 'adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  return model, criterion, optimizer\n"
      ],
      "metadata": {
        "id": "hFjcnFc1ismD"
      },
      "id": "hFjcnFc1ismD",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the network"
      ],
      "metadata": {
        "id": "KJ9sJEGCnryH"
      },
      "id": "KJ9sJEGCnryH"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_dataset ,criterion, optimizer, epochs):\n",
        "\n",
        "  epochs = 5  # Number of times the model will see the entire dataset\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_dataset:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n"
      ],
      "metadata": {
        "id": "aBq-0K5HoBqB"
      },
      "id": "aBq-0K5HoBqB",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the network"
      ],
      "metadata": {
        "id": "vrU9v8z0oNHT"
      },
      "id": "vrU9v8z0oNHT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**notes**\n",
        "outputs.data â†’ raw tensor values (we donâ€™t need gradient history).\n",
        "\n",
        "torch.max(tensor, dim=1) â†’ find the maximum along dimension 1 (the class scores).\n",
        "\n",
        "Returns (values, indices) â†’ values = max score, indices = where it occurred.\n",
        "\n",
        "_ means â€œignore values, we only care about indicesâ€.\n",
        "\n",
        "predicted shape = [batch_size], containing predicted class IDs.\n",
        "\n",
        "\n",
        "labels.size(0) = batch size (number of images in this batch).\n",
        "\n",
        "Add to total."
      ],
      "metadata": {
        "id": "9yEX1sRcsAxG"
      },
      "id": "9yEX1sRcsAxG"
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model,test_dataset):\n",
        "\n",
        "  correct = 0   # to keep track of right number of predictions\n",
        "  total = 0\n",
        "\n",
        "  # Normally, PyTorch tracks every operation for backpropagation.\n",
        "  # But in testing, we donâ€™t update weights â†’ we donâ€™t need gradients.\n",
        "\n",
        "  with torch.no_grad(): # No need to compute gradients\n",
        "    for images, labels in testloader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) # Index of max logit = predicted class\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "  print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "i6OKfBXmrCOy"
      },
      "id": "i6OKfBXmrCOy",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "41uWv4mqrw-D"
      },
      "id": "41uWv4mqrw-D"
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model, criterion, optimizer = create_model(\n",
        "    hidden_size= 128 ,\n",
        "    activation= 'relu' ,\n",
        "    optimizer= 'adam' ,\n",
        "    lr= 0.001\n",
        "    )\n",
        "\n",
        "# train\n",
        "\n",
        "train_model(model, trainloader, criterion, optimizer, epochs=5)\n",
        "\n",
        "# test\n",
        "test_model(model,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDYDNKo8xG6i",
        "outputId": "9688d7bb-02f7-4f46-d187-d549308cb5a7"
      },
      "id": "qDYDNKo8xG6i",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5017\n",
            "Epoch [2/5], Loss: 0.3808\n",
            "Epoch [3/5], Loss: 0.3424\n",
            "Epoch [4/5], Loss: 0.3149\n",
            "Epoch [5/5], Loss: 0.2996\n",
            "Test Accuracy: 86.44%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.44"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rIo8Pi2oxusm"
      },
      "id": "rIo8Pi2oxusm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "eOOWkS6v0o-s"
      },
      "id": "eOOWkS6v0o-s"
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model2, criterion2, optimizer2 = create_model(\n",
        "    hidden_size= 256 ,\n",
        "    activation= 'sigmoid' ,\n",
        "    optimizer= 'adam' ,\n",
        "    lr= 0.001\n",
        "    )\n",
        "\n",
        "# train\n",
        "\n",
        "train_model(model2, trainloader, criterion2, optimizer2, epochs=5)\n",
        "\n",
        "# test\n",
        "test_model(model2,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2542927-7ef4-4ba2-b47b-639ae9157d34",
        "id": "O83Xz-gp0o-t"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.5401\n",
            "Epoch [2/5], Loss: 0.3886\n",
            "Epoch [3/5], Loss: 0.3490\n",
            "Epoch [4/5], Loss: 0.3207\n",
            "Epoch [5/5], Loss: 0.3001\n",
            "Test Accuracy: 87.11%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87.11"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "id": "O83Xz-gp0o-t"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hpI-lAP20o-u"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hpI-lAP20o-u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ],
      "metadata": {
        "id": "NDT79xEm0r0R"
      },
      "id": "NDT79xEm0r0R"
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model3, criterion3, optimizer3 = create_model(\n",
        "    hidden_size= 128 ,\n",
        "    activation= 'sigmoid' ,\n",
        "    optimizer= 'sgd' ,\n",
        "    lr= 0.01\n",
        "    )\n",
        "\n",
        "# train\n",
        "\n",
        "train_model(model3, trainloader, criterion3, optimizer3, epochs=5)\n",
        "\n",
        "# test\n",
        "test_model(model3,testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81ac1b4-ae8d-43c5-8a3d-98f7c550bf8b",
        "id": "jc6DzBIj0r0S"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 1.5136\n",
            "Epoch [2/5], Loss: 0.9009\n",
            "Epoch [3/5], Loss: 0.7321\n",
            "Epoch [4/5], Loss: 0.6558\n",
            "Epoch [5/5], Loss: 0.6087\n",
            "Test Accuracy: 78.32%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78.32"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "id": "jc6DzBIj0r0S"
    },
    {
      "cell_type": "code",
      "source": [
        "# as we can see model 2 has best accuracy , so we save the best model\n",
        "# Save weights + hyperparams in one checkpoint\n",
        "torch.save({\n",
        "    \"hidden_size\": 256,\n",
        "    \"activation\": \"sigmoid\",\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"state_dict\": model2.state_dict()\n",
        "}, \"model2.pt\")\n",
        "\n",
        "print(\"Model saved as model2.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIqMfbuT0r0S",
        "outputId": "78e1541a-4332-4748-ccc1-fb0bfa6081ab"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as model2.pt\n"
          ]
        }
      ],
      "id": "oIqMfbuT0r0S"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLf3my8Q3ETA",
        "outputId": "a1c966d0-df00-4cd6-dd0f-7b77c2e1a476"
      },
      "id": "BLf3my8Q3ETA",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 808K\n",
            "drwxr-xr-x 3 root root 4.0K Aug 20 07:39 data\n",
            "-rw-r--r-- 1 root root 798K Aug 20 09:43 model2.pt\n",
            "drwxr-xr-x 1 root root 4.0K Aug 18 13:38 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzKpZgb83ewV"
      },
      "id": "NzKpZgb83ewV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}